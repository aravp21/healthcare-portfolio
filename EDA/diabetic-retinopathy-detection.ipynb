{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/992roMyN9tGcr85NIYaB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Diabetic Retinopathy Detection\n","\n","Dataset found here: https://www.kaggle.com/c/diabetic-retinopathy-detection/data\n","\n","Goal is to predict severity of patient's diabetic retinopathy given retina images under varying conditions"],"metadata":{"id":"6cuEy8MIVYCA"}},{"cell_type":"code","source":["### Untested due to size of dataset and hardware training limitations ###\n","import os\n","import sys\n","import pandas as pd\n","import numpy as np\n","\n","from PIL import ImageFile, Image\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","from skimage import io, img_as_ubyte\n","from skimage.transform import resize, rotate\n","import cv2"],"metadata":{"id":"m2ak9SqGh2z1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_directory(directory):\n","  if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","def get_img_list(path):\n","  return [i for i in os.listdir(path) if i != '.DS_Store']\n","\n","def resize_images(path, new_path, img_size=256):\n","  create_directory(new_path)\n","  dirs = get_img_list(path)\n","  total = 0\n","\n","  for item in dirs:\n","    img = io.imread(path+item)\n","    img = resize(img, (256,256))\n","    io.imsave(str(new_path + item), img_as_ubyte(img))\n","    total += 1\n","    print(f\"Saving: {item, total}\")\n","\n","def rotate_images(path, deg_rotate, img_l):\n","  for l in img_l:\n","    img = io.imread(path + str(l) + '.jpeg')\n","    img = rotate(img, deg_rotate)\n","    io.imsave(path + str(l) + '_' + str(deg_rotate) + '.jpeg', img_as_ubyte(img))\n","\n","def mirror_images(path, mirror_dir, img_l):\n","  for l in img_l:\n","    img = cv2.imread(path + str(l) + '.jpeg')\n","    img = cv2.flip(img, mirror_dir)\n","    cv2.imwrite(path + str(l) + '_mir' + '.jpeg',  img_as_ubyte(img)) "],"metadata":{"id":"6TZoicaniAXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resize_images(path='./train/original_data/', new_path='./train/preprocessed_data/', img_size=256)\n","\n","trainLabels = pd.read_csv('./train/trainLabels_original.csv')\n","trainLabels['image'] = trainLabels['image'].str.rstrip('.jpeg')\n","trainLabels_no_DR = trainLabels[trainLabels['level'] == 0]\n","trainLabels_DR = trainLabels[trainLabels['level'] >= 1]\n","\n","img_l_no_DR = [i for i in trainLabels_no_DR['image']]\n","img_l_DR = [i for i in trainLabels_DR['image']]\n","\n","# mirror images with no DR once\n","print(\"Mirroring Non-DR Images\")\n","mirror_images('./train/preprocessed_data/', 1, img_l_no_DR)\n","\n","# rotate all images with any level of DR\n","print(\"Rotating 90 Degrees\")\n","rotate_images('./train/preprocessed_data/', 90, img_l_DR)\n","\n","print(\"Rotating 120 Degrees\")\n","rotate_images('./train/preprocessed_data/', 120, img_l_DR)\n","\n","print(\"Rotating 180 Degrees\")\n","rotate_images('./train/preprocessed_data/', 180, img_l_DR)\n","\n","print(\"Rotating 270 Degrees\")\n","rotate_images('./train/preprocessed_data/', 270, img_l_DR)\n","\n","print(\"Mirroring DR Images\")\n","mirror_images('./train/preprocessed_data/', 0, img_l_DR)\n","\n","trainLabels = pd.read_csv('./train/trainLabels_original.csv')\n","\n","img_l = get_img_list('./train/preprocessed_data/')\n","\n","trainLabels['image'] = trainLabels.loc[:, 'image'].apply(lambda x: x + '.jpeg')\n","new_trainLabels = pd.DataFrame({'image': img_l})\n","new_trainLabels['image2'] = new_trainLabels.image\n","\n","# remove suffix from image names\n","new_trainLabels['image2'] = new_trainLabels.loc[:, 'image2'].apply(lambda x: '_'.join(x.split('_')[0:2]).strip('.jpeg') + '.jpeg')\n","new_trainLabels.columns = ['train_image_name', 'image']\n","\n","trainLabels = pd.merge(trainLabels, new_trainLabels, how='outer', on='image')\n","trainLabels = trainLabels.dropna()\n","trainLabels.to_csv('./train/trainLabels_augmented.csv', index=False, header=True)"],"metadata":{"id":"GHlAIXhpyC_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","from keras.utils import to_categorical\n","\n","nb_classes = 2\n","labels = pd.read_csv('./train/trainLabels_augmented.csv')\n","y = np.array([1 if l >= 1 else 0 for l in labels['level']]) if (nb_classes == 2) else np.array([l for l in labels['level']])\n","y = to_categorical(y, nb_classes)\n","\n","img_l  = np.array([l for l in labels['train_image_name']])\n","X = np.array([np.array(Image.open('./train/preprocessed_data/' + img)) for img in img_l]).astype(np.float32)\n","X /= 255.0"],"metadata":{"id":"LrVHjrlZ8FT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n","X_train_raw = np.array(X_train)\n","y_train_raw = np.array(y_train)\n","X_test_raw = np.array(X_test)\n","y_test_raw = np.array(y_test)"],"metadata":{"id":"lvtKhjpA_mL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Dense, Dropout, Flatten, Input \n","from keras.models import Model\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.pooling import MaxPooling2D\n","\n","input = Input(shape=(256, 256, 3))\n","conv1 = Conv2D(32, kernel_size=4, activation='relu')(input)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","conv2 = Conv2D(16, kernel_size=4, activation='relu')(pool1)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","flat = Flatten()(pool2)\n","hidden1 = Dense(10, activation='relu')(flat)\n","output = Dense(1, activation='sigmoid')(hidden1)\n","model = Model(inputs=input, outputs=output)\n","\n","# model = keras.Sequential([keras.layers.Flatten(input_shape=(786, 786, 3)), keras.layers.Dense(128, activation=tf.nn.relu), \n","        # keras.layers.Dense(10, activation=tf.nn.softmax)])"],"metadata":{"id":"g6w903fZAOpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(X_train_raw, y_train_raw, epochs=5)"],"metadata":{"id":"tmpN3mWqAnai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss, acc = model.evaluate(X_test_raw, y_test_raw)\n","print(f\"Test Loss: {loss}, Test Accuracy: {acc}\")"],"metadata":{"id":"Pkhxh20DBFYJ"},"execution_count":null,"outputs":[]}]}